{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea4ddcb",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; border-radius:8px; padding:12px; text-align:center;\">\n",
    "\n",
    "# **PRACTICA 2: Árboles y Ensembles**\n",
    "\n",
    "</div>\n",
    "\n",
    "*Aprendizaje Automático*\n",
    "\n",
    "---\n",
    "\n",
    "**Grupo:** G-7312  \n",
    "**Número de pareja:** 01  \n",
    "**Miembros:**  \n",
    "- Leire Bernárdez Vázquez  \n",
    "- Carmen Reiné Rueda\n",
    "\n",
    "---\n",
    "\n",
    "### **Importaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9dba5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a805c",
   "metadata": {},
   "source": [
    "---\n",
    "**1. Cargue los datos del problema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "343b57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Covertype dataset\n",
    "cov_type = fetch_covtype()\n",
    "# Separate the features and the target variable\n",
    "X = cov_type.data\n",
    "y = cov_type.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd92d60",
   "metadata": {},
   "source": [
    "**2. Separe los datos en training (50 %) y test (50 %)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc7d1c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3411fd",
   "metadata": {},
   "source": [
    "No hace falta escalarlo, lo dice la teacher (los árboles se tragan todo lo que les des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401128f",
   "metadata": {},
   "source": [
    "**3. Utilice la clase DecisionTreeClassifier de Sklearn para resolver el problema\n",
    "y dé un resultado de test usando la m ́etrica que considere oportuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "485a28a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.35816127721975 %\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "porcentaje = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", porcentaje*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02190d",
   "metadata": {},
   "source": [
    "**4. ¿Había missing values en nuestro problema? ¿Qué efecto tendría en los árboles no completar los missing values ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29705ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X_train).sum()==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ffbee",
   "metadata": {},
   "source": [
    "Si existieran y no se imputaran, DecisionTreeClassifier daría error al entrenar, porque los árboles no soportan missing values; requieren que todos los datos estén completos para funcionar. Para solucionar este problema, se podrían imputar con media, mediana o un valor concreto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f58d6a",
   "metadata": {},
   "source": [
    "**5. ¿Con qué parémetro podría controlarse la profundidad del ́arbol? ¿Qué ocurre si un ́arbol se inicializa sin dar un valor concreto a ese parámetro? ¿Crees que sería una buena práctica no darle ningún valor?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2256c1",
   "metadata": {},
   "source": [
    "a) La profundidad máxima del árbol se controla con el parámetro max_depth directamente, que por defecto es max_depth=None. Sin embargo, también se puede controlar indirectamente con min_samples_split, que no divide un nodo si tiene menos muestras que las requeridas, y con min_samples_leaf, que obliga a que cada hoja tenga un mínimo de muestras para evitar que existan ramas muy profundas con pocas muestras. Por lo tanto, con estos valores se reduce la profundidad máxima alcanzada.\n",
    "\n",
    "b) Crecería tanto como datos se le pasaran sin ningún tipo de límite.\n",
    "\n",
    "c) No, debido a que sin un límite establecido, los árboles grandes consumen más memoria, tardan más en entrenar y tienden a sobreajustarse más fácilmente. Con lo cual, sería importante definir un max_depth razonable teniendo en cuenta los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d172a45d",
   "metadata": {},
   "source": [
    "**6. ¿Son sensibles los ́arboles al desequilibrio entre clases?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aabafc",
   "metadata": {},
   "source": [
    "Sí, los árboles de decisión se ven afectados cuando las clases están desbalanceadas. Tratan de que cada hoja tenga solo un tipo de clase, así que cuando una clase es mayoritaria, las divisiones tienden a favorecerla. Esto puede hacer que las clases minoritarias queden mezcladas o se clasifiquen mal.\n",
    "\n",
    "Si no se corrige este desequilibrio, el árbol aprenderá principalmente la clase mayoritaria y puede fallar al predecir las clases minoritarias, aunque acierte mucho con la clase que domina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329e056",
   "metadata": {},
   "source": [
    "**7. ¿Existe desequilibrio entre las clases de nuestro problema? ¿Con qué parámetro de la clase DecisionTreeClassifier podrías corregirlo?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b18715e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 211840, 2: 283301, 3: 35754, 4: 2747, 5: 9493, 6: 17367, 7: 20510}\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(y)  # y debe ser enteros >=0\n",
    "print({i: count for i, count in enumerate(counts) if count > 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e21fe9c",
   "metadata": {},
   "source": [
    "a) Para comprobar si existe desequilibrio entre las clases del dataset Covtype, hemos utilizado la función np.bincount sobre las etiquetas de cada muestra.  \n",
    "\n",
    "   Esta función nos permite contar cuántas muestras hay de cada clase y así analizar la distribución de los datos. Los resultados muestran que algunas clases tienen muchas más muestras que otras, confirmando que sí existe desequilibrio entre las clases.  \n",
    "\n",
    "b) Podríamos corregirlo utilizando el parámetro class_weight='balanced  en DecisionTreeClassifier, que ajusta automáticamente los pesos de cada clase en función de su frecuencia en el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23981d2",
   "metadata": {},
   "source": [
    "**8. ¿Cuál es la diferencia entre los parámetros min samples split y min samples leaf ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ca953",
   "metadata": {},
   "source": [
    " **`min_samples_split`** \n",
    "\n",
    "**Definición según la documentación:** El número mínimo de muestras necesarias para dividir un nodo interno.\n",
    "\n",
    "Este parámetro decide si un nodo se puede dividir. \n",
    "- Si el grupo de datos tiene suficientes muestras según el valor indicado, el nodo se divide en dos o más partes.  \n",
    "- Si no tiene suficientes, el nodo se queda igual y se convierte en hoja.\n",
    "\n",
    "\n",
    "**`min_samples_leaf`**  \n",
    "\n",
    "**Definición según la documentación:** El número mínimo de muestras necesarias para estar en un nodo hoja. Un punto de división a cualquier profundidad solo se considerará si sale a menos muestras de entrenamiento en cada una de las muestras de entrenamiento izquierdo y ramas derechas. Esto puede tener el efecto de suavizar el modelo\n",
    "\n",
    "Este parámetro se utiliza después de dividir un nodo para comprobar si cada hoja tiene suficientes muestras.  \n",
    "- Si alguna hoja tiene menos muestras que el valor indicado, la división no se realiza.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520151e",
   "metadata": {},
   "source": [
    "**9. ¿Para qué sirve el parémetro criterion, qué valores puede tomar y qué significa o representa cada uno de esos valores?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165a8ad",
   "metadata": {},
   "source": [
    "El parámetro criterion sirve para decidir qué tan buena es una división en un árbol de decisión. Es decir, indica cómo medir la calidad de los splits.\n",
    "\n",
    "Los valores que puede tomar son:\n",
    "\n",
    "- **gini** → utiliza el índice de Gini, que mide la impureza de un nodo.  \n",
    "  Busca que cada hoja tenga muestras de la misma clase lo más posible.  \n",
    "\n",
    "- **entropy** → utiliza la ganancia de información de Shannon.  \n",
    "  Calcula cuánto disminuye la incertidumbre o desorden al hacer un split.  \n",
    "  \n",
    "- **log_loss** → también mide la ganancia de información, pero usando pérdida logarítmica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff286d",
   "metadata": {},
   "source": [
    "**10. El ́arbol entrenado, ¿realiza splits utilizando todas las variables disponibles?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3450d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables usadas con importancia: [(0, 0.3387193675902033), (1, 0.02734065294627229), (2, 0.017110056184974496), (3, 0.060196787910735905), (4, 0.047588420293639556), (5, 0.14774537629887685), (6, 0.03182038149798011), (7, 0.033703739434048204), (8, 0.02477366924852275), (9, 0.144395346998855), (10, 0.009571813426162762), (11, 0.0023373991008695996), (12, 0.012507758498829688), (13, 0.0016874797520611059), (14, 0.00029190964461878833), (15, 0.009824746700157672), (16, 0.001370541747133486), (17, 0.01125754414967012), (18, 0.0002653376729426192), (19, 0.0005795223900614763), (22, 0.00011716541185293037), (23, 0.002609083803495816), (24, 0.0018839788104798813), (25, 0.0008602858986689834), (26, 0.0034171015516396533), (27, 0.00011945702525846545), (28, 1.0886440090901796e-05), (29, 0.000779219015968397), (30, 0.0012164764635362703), (31, 1.8129399786179915e-05), (32, 0.0009461197934352617), (33, 0.002977966855033216), (34, 0.0002886730699214571), (35, 0.00694562633474603), (36, 0.008764931763823005), (37, 0.0038909989935176715), (38, 0.0001043141643040966), (39, 9.29343837179204e-05), (40, 0.0007656927297130585), (41, 0.00014964322450203245), (42, 0.00654634277593775), (43, 0.0026945661113239876), (44, 0.005673019784461972), (45, 0.012977437757725472), (46, 0.005081713567694201), (47, 0.0002698693144106678), (48, 0.001066143562381183), (49, 5.131106273029018e-05), (50, 0.00015373163499381707), (51, 0.0020378932926366023), (52, 0.003567711519382235), (53, 0.0008337229962148583)]\n"
     ]
    }
   ],
   "source": [
    "importances = decision_tree.feature_importances_\n",
    "used_features = [(i, imp) for i, imp in enumerate(importances) if imp > 0]\n",
    "print(\"Variables usadas con importancia:\", used_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c186c62",
   "metadata": {},
   "source": [
    "Cada tupla (índice, importancia) indica qué columna se utilizó en algún split del árbol y cuánto aportó a la decisión de dividir los nodos.\n",
    "\n",
    "Observando las importancias de las variables de nuestro árbol:\n",
    "\n",
    "- No todas las variables se utilizan en los splits.  \n",
    "- Solo se usan aquellas que aportan información útil para separar las clases, mientras que las demás quedan con importancia 0 y no aparecen en ningún nodo.  \n",
    "- Aunque el árbol analiza todas las variables disponibles, solo mantiene en el modelo final las que realmente ayudan a mejorar la clasificación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b88d4",
   "metadata": {},
   "source": [
    "**11. ¿Se le ocurre alguna forma de crear un selector de atributos a partir de un árbol de clasificación?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91a3ff",
   "metadata": {},
   "source": [
    "Aprovechando la importancia de cada variable feature_importances, podemos utilizar el árbol de decisión como selector de atributos.\n",
    "\n",
    "- Manteniendo únicamente las variables que realmente aportan información al modelo.  \n",
    "- Las variables con importancia 0 o muy baja pueden eliminarse, ya que no influyen en los splits.  \n",
    "- Esto permite reducir la dimensionalidad, simplificar el modelo e incluso en algunos casos mejorar la generalización.\n",
    "\n",
    "En Scikit-Learn se puede hacer fácilmente con SelectFromModel usando el árbol entrenado `decision_tree´.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199f75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de variables originales: 54\n",
      "Número de variables seleccionadas: 13\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(decision_tree, threshold=0.01, prefit=True)\n",
    "X_selected = selector.transform(X)\n",
    "\n",
    "print(f\"Número de variables originales: {X.shape[1]}\")\n",
    "print(f\"Número de variables seleccionadas: {X_selected.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c07117",
   "metadata": {},
   "source": [
    "SelectFromModel mira decision_tree.feature_importances_ y compara cada valor con  threshold = 0,01.  \n",
    "Si la importancia es mayor o igual al threshold, se mantiene; si es menor, se descarta.  \n",
    "Al hacer X_selected = selector.transform(X) conservamos solo las columnas importantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45baaa1",
   "metadata": {},
   "source": [
    "\n",
    "### **2. Regresión mediante árboles de regresión**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dd13c",
   "metadata": {},
   "source": [
    "#### **2.1. Obtención de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20009eb1",
   "metadata": {},
   "source": [
    "**Descargue los datos de Sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae91509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe3dfc",
   "metadata": {},
   "source": [
    "**Separe los datos en training (50 %) test (50 %) y realice el preprocesado de los\n",
    "datos que estime conveniente teniendo en cuenta que el modelo de aprendizaje con\n",
    "el que va a tratar de resolver el problema es un  ́arbol de regresión. Finalmente\n",
    "responda a las siguientes preguntas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e919c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81523487",
   "metadata": {},
   "source": [
    "**1. ¿Podría trabajar un arbol de regresión con missing values?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2f767",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55368b3f",
   "metadata": {},
   "source": [
    "**2. ¿Es sensible un ́arbol de regresión a las magnitudes de los atributos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60361c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28ec44f9",
   "metadata": {},
   "source": [
    "**3. ¿Es sensible un árbol de regresión a la distribución de las etiquetas?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69f63c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab720984",
   "metadata": {},
   "source": [
    "#### **2.2 Implementación de un árbol de regresión**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff440f8",
   "metadata": {},
   "source": [
    "**1. Construya una clase Nodo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44595126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe435e40",
   "metadata": {},
   "source": [
    "**2. Construya la clase RegressionTree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d477de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7988ec4e",
   "metadata": {},
   "source": [
    "#### **2.3. Nos enfrentamos al problema de California Housing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137eebc",
   "metadata": {},
   "source": [
    "**1. ¿Cómo evoluciona el error de training y test conforme se aumenta la profundidad del  ́arbol? Base su razonamiento en dos gráficas obtenidas con matplotlib.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebca09c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd82b034",
   "metadata": {},
   "source": [
    "**2. ¿Sobre qué parámetros tendría sentido realizar cross-validation en nuestro modelo?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f0dbf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d98a3a8",
   "metadata": {},
   "source": [
    "**3. Tome un par de muestras y utilizando el método decision_path(x) justifique la predicción dada. Como habrá comprobado, el método decision_path(x) devuelve una lista ordenada de argumentos, suponga que esa lista se desordena: ¿seguiría siendo válida la interpretación de la predicción?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c579ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20c64217",
   "metadata": {},
   "source": [
    "**4. Para una muestra idéntica a la del apartado anterior, si se entrenara un nuevo árbol, ¿la justificación de su predicción sería la misma?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae33df2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24277e32",
   "metadata": {},
   "source": [
    "**5. Suponga que divide el conjunto de train en dos mitades, entrena dos árboles distintos, uno con cada mitad, y toma una muestra de test. ¿Sería la predicción de la muestra igual en cada árbol? ¿Y la interpretación obtenida con decision_path(x)? ¿Qué repercusión en la interpretación tendría esa situación?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f407f25",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b409adc",
   "metadata": {},
   "source": [
    "**6. Utilice la clase DecisionTreeRegressor de Sklearn para resolver de nuevo el problema. Compare el score de ambos modelos y, para alguna muestra, el resultado de decision_path(x) de ambos árboles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f64d24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cf1ff5b",
   "metadata": {},
   "source": [
    "**7. En base a su implementación ¿cuál es el coste computacional teórico de entrenar un árbol? ¿Y cuál sería el coste en predicción? ¿Y el coste en memoria? Si tuviera que resolver un problema con un conjunto de datos de gran volumen, ¿qué preferiría usar, un árbol o un modelo de regresión lineal?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810433b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e63c150",
   "metadata": {},
   "source": [
    "\n",
    "### **3. Ensembles**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
